{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries have been successfully imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import lxml.html \n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "print('All required libraries have been successfully imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_only_page(url, filename):\n",
    "    \"\"\"\"\"\n",
    "    Input: \n",
    "    -----\n",
    "        url- URL of the webpage to be downloaded to local file system.\n",
    "        filename- Desired filename to be associated with the downloaded webpage.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "        return nothing.\n",
    "    \n",
    "    Functionality:\n",
    "    -------------\n",
    "        Request for the webpage based on URL and download it to a local directory.\n",
    "    \"\"\"\"\"\n",
    "    # Request to download the html page\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Save downloaded page as a text file\n",
    "    with open(filename, mode='wb') as file:     \n",
    "        file.write(r.content)\n",
    "\n",
    "    print('TripAdvisor- hotel HTML page downloaded successfully..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_html_page(url, count_file):\n",
    "    \"\"\"\"\"\n",
    "    Input: \n",
    "    -----\n",
    "        url- URL of the webpage to be downloaded to local file system.\n",
    "        count_file- file number or file count, used to create a filename to be stored in local directory.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "        return lxml.etree instance(html) and the updated count aka file number.\n",
    "    \n",
    "    Functionality:\n",
    "    -------------\n",
    "        - Request for the webpage based on URL and download it to a local directory.\n",
    "        - Create lxml.etree instance of the webpage downloaded, inorder to help parse it.\n",
    "    \"\"\"\"\"\n",
    "     # Request to download the html page\n",
    "    r = requests.get(url)\n",
    "    count_file += 1\n",
    "    # Save downloaded page as a text file\n",
    "    filename = 'file:///home/atharvas/Desktop/NIAGARA.html'+ str(count_file) + '.txt'\n",
    "    with open(filename, mode='wb') as file:     \n",
    "        file.write(r.content)\n",
    "\n",
    "    print('TripAdvisor- hotel HTML page downloaded successfully..')\n",
    "    \n",
    "    # Open saved file to parse it.\n",
    "    with open(filename,'r') as fileread:\n",
    "        html = etree.HTML(fileread.read())\n",
    "    \n",
    "    # Parse the HTML page as a tree structure\n",
    "    result = etree.tostring(html, pretty_print=True, method=\"html\")\n",
    "    print('File read successfully..')\n",
    "    \n",
    "    return html, count_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parse_file(filename):\n",
    "    \"\"\"\"\"\n",
    "    Input: \n",
    "    -----\n",
    "        filename- Filename used to store the desired webpage in local directory.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "        return lxml.etree instance(html) and the updated count/file number.\n",
    "    \n",
    "    Functionality:\n",
    "    -------------\n",
    "        - Read the desired file from local directory.\n",
    "        - Create lxml.etree instance of the webpage downloaded inorder to help parse it.\n",
    "    \"\"\"\"\"\n",
    "    # Open saved file to parse it.\n",
    "    with open(filename,'r') as fileread:\n",
    "        html = etree.HTML(fileread.read())\n",
    "    \n",
    "    # Parse the HTML page as a tree structure\n",
    "    result = etree.tostring(html, pretty_print=True, method=\"html\")\n",
    "    print('File read successfully..')\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotel_url(count, html):\n",
    "    \"\"\"\"\"\n",
    "    Input: \n",
    "    -----\n",
    "        count- Number of desired elements(here the 'divs' containing hotel URLs) present in the downloaded page.\n",
    "        html- lxml.etree instance(html), used to parse the file.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "        return the extracted full hotel URL(hotel_url) from the base webpage.\n",
    "    \n",
    "    Functionality:\n",
    "    -------------\n",
    "        - Parse the downloaded file using html.etree and XPATH to obtain hotel URLs embedded in the mainpage.\n",
    "        - This function considers only exact search results for a given category of hotels.\n",
    "    \"\"\"\"\"\n",
    "    hotel_url = []\n",
    "    double_count = 0\n",
    "    num_ad = 2 # to counter ads intbetween\n",
    "    iter_val = 0\n",
    "    \n",
    "    # Parse html page to get the urls for nested webpages.\n",
    "    for element in range(int(count)):\n",
    "        iter_val = element + 1\n",
    "        # Adjust numbering based on webpage structure.\n",
    "        if iter_val <= 4 :\n",
    "            iter_val = iter_val\n",
    "        elif iter_val == int(count):\n",
    "            iter_val += int(double_count * num_ad) \n",
    "        else:\n",
    "            if (iter_val % 5 == 0) & (iter_val != int(count)):\n",
    "                double_count += 1\n",
    "                iter_val += int(double_count * num_ad)\n",
    "            else:\n",
    "                iter_val += int(double_count * num_ad)\n",
    "                \n",
    "        # Use xpath to retrieve the necessary content.\n",
    "        XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]/div/div[' + str(iter_val) + ']/div/div[1]/@data-url')\n",
    "\n",
    "        if str(XPATH)[2:-2] == '':\n",
    "            XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]/div[' + str(iter_val) + ']/div/div[1]/@data-url')\n",
    "        \n",
    "        if str(XPATH)[2:-2] == '':\n",
    "            XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]/div/div[' + str(iter_val) + ']/div/div/div/div[1]/@data-url')\n",
    "        \n",
    "        hotel_url.append('https://www.tripadvisor.ca' + str(XPATH)[2:-2])\n",
    "    \n",
    "    return hotel_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotel_url_related(count, html):\n",
    "    \"\"\"\"\"\n",
    "    Input: \n",
    "    -----\n",
    "        count- Number of desired elements(here the 'divs' containing hotel URLs) present in the downloaded page.\n",
    "        html- lxml.etree instance(html), used to parse the file.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "        return the extracted full hotel URL(hotel_url) from the base webpage.\n",
    "    \n",
    "    Functionality:\n",
    "    -------------\n",
    "        - Parse the downloaded file using html.etree and XPATH to obtain hotel URLs embedded in the mainpage.\n",
    "        - This function considers only related search results (if exact results are nil, this will be called)\n",
    "          for a given category of hotels.\n",
    "    \"\"\"\"\"\n",
    "    hotel_url = []\n",
    "    double_count = 0\n",
    "    num_ad = 2 # to counter ads intbetween\n",
    "    iter_val = 0\n",
    "    \n",
    "    # Parse html page to get the urls for nested webpages.\n",
    "    for element in range(int(count)):\n",
    "        iter_val = element + 1\n",
    "        # Adjust numbering based on webpage structure.\n",
    "        if iter_val <= 4 :\n",
    "            iter_val = iter_val\n",
    "        elif iter_val == int(count):\n",
    "            iter_val += int(double_count * num_ad) \n",
    "        else:\n",
    "            if (iter_val % 5 == 0) & (iter_val != int(count)):\n",
    "                double_count += 1\n",
    "                iter_val += int(double_count * num_ad)\n",
    "            else:\n",
    "                iter_val += int(double_count * num_ad)\n",
    "        value = iter_val + 1\n",
    "    \n",
    "        # Use xpath to retrieve the necessary content.\n",
    "        XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_filtered_out_hotels_0\"]/div/div[' + str(value) + ']/div/div[1]/@data-url')\n",
    "        \n",
    "        if str(XPATH)[2:-2] == '':\n",
    "            XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_filtered_out_hotels_0\"]/div[' + str(value) + ']/div/div[1]/@data-url')\n",
    "\n",
    "        hotel_url.append('https://www.tripadvisor.ca' + str(XPATH)[2:-2])\n",
    "    \n",
    "    return hotel_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotel_url_nomatches(count, html):\n",
    "    \"\"\"\"\"\n",
    "    Input: \n",
    "    -----\n",
    "        count- Number of desired elements(here the 'divs' containing hotel URLs) present in the downloaded page.\n",
    "        html- lxml.etree instance(html), used to parse the file.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "        return the extracted full hotel URL(hotel_url) from the base webpage.\n",
    "    \n",
    "    Functionality:\n",
    "    -------------\n",
    "        - Parse the downloaded file using html.etree and XPATH to obtain hotel URLs embedded in the mainpage.\n",
    "        - This function considers only other search results (if exact results and related results for a page are nil, \n",
    "          this will be called) for a given category of hotels.\n",
    "    \"\"\"\"\"\n",
    "    hotel_url = []\n",
    "    double_count = 0\n",
    "    num_ad = 2 # to counter ads intbetween\n",
    "    iter_val = 0\n",
    "    \n",
    "    # Parse html page to get the urls for nested webpages.\n",
    "    for element in range(int(count)):\n",
    "        iter_val = element + 1\n",
    "        # Adjust numbering based on webpage structure.\n",
    "        if iter_val <= 4 :\n",
    "            iter_val = iter_val\n",
    "        elif iter_val == int(count):\n",
    "            iter_val += int(double_count * num_ad) \n",
    "        else:\n",
    "            if (iter_val % 5 == 0) & (iter_val != int(count)):\n",
    "                double_count += 1\n",
    "                iter_val += int(double_count * num_ad)\n",
    "            else:\n",
    "                iter_val += int(double_count * num_ad)\n",
    "    \n",
    "        # Use xpath to retrieve the necessary content.\n",
    "        XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_ab_hotels_sponsored_0\"]/div[' + str(iter_val) + ']/div/div[1]/@data-url')\n",
    "        \n",
    "        if str(XPATH)[2:-2] == '':\n",
    "            XPATH =  html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_ab_hotels_sponsored_0\"]/div[' + str(iter_val) + ']/div/div/div/div[1]/@data-url')\n",
    "\n",
    "        hotel_url.append('https://www.tripadvisor.ca' + str(XPATH)[2:-2])\n",
    "    \n",
    "    return hotel_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file:///home/atharvas/Desktop/NIAGARA.html1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c0adc388028c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Request html page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.tripadvisor.ca/Hotels-g153339-Canada-Hotels.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_html_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create xpath to access necessary content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-de173ac70f17>\u001b[0m in \u001b[0;36mdownload_html_page\u001b[0;34m(url, count_file)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Save downloaded page as a text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file:///home/atharvas/Desktop/NIAGARA.html'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file:///home/atharvas/Desktop/NIAGARA.html1.txt'"
     ]
    }
   ],
   "source": [
    "# Extract related content from the tree using XPath for the MainPage of TripAdvisor hotels canada.\n",
    "count_file = 0\n",
    "\n",
    "# Request html page\n",
    "url = str('https://www.tripadvisor.ca/Hotels-g153339-Canada-Hotels.html')\n",
    "html, count_file = download_html_page(url, count_file)\n",
    "\n",
    "# Create xpath to access necessary content\n",
    "XPATH_MAINPAGE = '//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]//div[@class=\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"]'\n",
    "hotel_main_page = html.xpath(XPATH_MAINPAGE)\n",
    "\n",
    "# Get count of elements of interest in html page\n",
    "count = html.xpath('count(//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]//div[@class=\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"])')\n",
    "# print(count)\n",
    "\n",
    "# Get the parsed html etree\n",
    "hotel_url_returned = get_hotel_url(count, html)\n",
    "print('Content Extracted..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import libraries\n",
    "# import os\n",
    "# import requests\n",
    "# import json\n",
    "# import re\n",
    "# import sys\n",
    "# import lxml.html \n",
    "# from lxml import html\n",
    "# from lxml import etree\n",
    "# import csv\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from geopy.geocoders import Nominatim\n",
    "\n",
    "# print('All required libraries have been successfully imported.')\n",
    "# All required libraries have been successfully imported.\n",
    "# In [4]:\n",
    "# def download_only_page(url, filename):\n",
    "#     \"\"\"\"\"\n",
    "#     Input: \n",
    "#     -----\n",
    "#         url- URL of the webpage to be downloaded to local file system.\n",
    "#         filename- Desired filename to be associated with the downloaded webpage.\n",
    "    \n",
    "#     Output:\n",
    "#     ------\n",
    "#         return nothing.\n",
    "    \n",
    "#     Functionality:\n",
    "#     -------------\n",
    "#         Request for the webpage based on URL and download it to a local directory.\n",
    "#     \"\"\"\"\"\n",
    "#     # Request to download the html page\n",
    "#     r = requests.get(url)\n",
    "    \n",
    "#     # Save downloaded page as a text file\n",
    "#     with open(filename, mode='wb') as file:     \n",
    "#         file.write(r.content)\n",
    "\n",
    "#     print('TripAdvisor- hotel HTML page downloaded successfully..')\n",
    "# In [5]:\n",
    "# def download_html_page(url, count_file):\n",
    "#     \"\"\"\"\"\n",
    "#     Input: \n",
    "#     -----\n",
    "#         url- URL of the webpage to be downloaded to local file system.\n",
    "#         count_file- file number or file count, used to create a filename to be stored in local directory.\n",
    "    \n",
    "#     Output:\n",
    "#     ------\n",
    "#         return lxml.etree instance(html) and the updated count aka file number.\n",
    "    \n",
    "#     Functionality:\n",
    "#     -------------\n",
    "#         - Request for the webpage based on URL and download it to a local directory.\n",
    "#         - Create lxml.etree instance of the webpage downloaded, inorder to help parse it.\n",
    "#     \"\"\"\"\"\n",
    "#      # Request to download the html page\n",
    "#     r = requests.get(url)\n",
    "#     count_file += 1\n",
    "#     # Save downloaded page as a text file\n",
    "#     filename = 'Project-Dataset/tripadvisor_canada_hotels'+ str(count_file) + '.txt'\n",
    "#     with open(filename, mode='wb') as file:     \n",
    "#         file.write(r.content)\n",
    "\n",
    "#     print('TripAdvisor- hotel HTML page downloaded successfully..')\n",
    "    \n",
    "#     # Open saved file to parse it.\n",
    "#     with open(filename,'r') as fileread:\n",
    "#         html = etree.HTML(fileread.read())\n",
    "    \n",
    "#     # Parse the HTML page as a tree structure\n",
    "#     result = etree.tostring(html, pretty_print=True, method=\"html\")\n",
    "#     print('File read successfully..')\n",
    "    \n",
    "#     return html, count_file\n",
    "# In [8]:\n",
    "# def read_parse_file(filename):\n",
    "#     \"\"\"\"\"\n",
    "#     Input: \n",
    "#     -----\n",
    "#         filename- Filename used to store the desired webpage in local directory.\n",
    "    \n",
    "#     Output:\n",
    "#     ------\n",
    "#         return lxml.etree instance(html) and the updated count/file number.\n",
    "    \n",
    "#     Functionality:\n",
    "#     -------------\n",
    "#         - Read the desired file from local directory.\n",
    "#         - Create lxml.etree instance of the webpage downloaded inorder to help parse it.\n",
    "#     \"\"\"\"\"\n",
    "#     # Open saved file to parse it.\n",
    "#     with open(filename,'r') as fileread:\n",
    "#         html = etree.HTML(fileread.read())\n",
    "    \n",
    "#     # Parse the HTML page as a tree structure\n",
    "#     result = etree.tostring(html, pretty_print=True, method=\"html\")\n",
    "#     print('File read successfully..')\n",
    "    \n",
    "#     return html\n",
    "# In [7]:\n",
    "# def get_hotel_url(count, html):\n",
    "#     \"\"\"\"\"\n",
    "#     Input: \n",
    "#     -----\n",
    "#         count- Number of desired elements(here the 'divs' containing hotel URLs) present in the downloaded page.\n",
    "#         html- lxml.etree instance(html), used to parse the file.\n",
    "    \n",
    "#     Output:\n",
    "#     ------\n",
    "#         return the extracted full hotel URL(hotel_url) from the base webpage.\n",
    "    \n",
    "#     Functionality:\n",
    "#     -------------\n",
    "#         - Parse the downloaded file using html.etree and XPATH to obtain hotel URLs embedded in the mainpage.\n",
    "#         - This function considers only exact search results for a given category of hotels.\n",
    "#     \"\"\"\"\"\n",
    "#     hotel_url = []\n",
    "#     double_count = 0\n",
    "#     num_ad = 2 # to counter ads intbetween\n",
    "#     iter_val = 0\n",
    "    \n",
    "#     # Parse html page to get the urls for nested webpages.\n",
    "#     for element in range(int(count)):\n",
    "#         iter_val = element + 1\n",
    "#         # Adjust numbering based on webpage structure.\n",
    "#         if iter_val <= 4 :\n",
    "#             iter_val = iter_val\n",
    "#         elif iter_val == int(count):\n",
    "#             iter_val += int(double_count * num_ad) \n",
    "#         else:\n",
    "#             if (iter_val % 5 == 0) & (iter_val != int(count)):\n",
    "#                 double_count += 1\n",
    "#                 iter_val += int(double_count * num_ad)\n",
    "#             else:\n",
    "#                 iter_val += int(double_count * num_ad)\n",
    "                \n",
    "#         # Use xpath to retrieve the necessary content.\n",
    "#         XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]/div/div[' + str(iter_val) + ']/div/div[1]/@data-url')\n",
    "\n",
    "#         if str(XPATH)[2:-2] == '':\n",
    "#             XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]/div[' + str(iter_val) + ']/div/div[1]/@data-url')\n",
    "        \n",
    "#         if str(XPATH)[2:-2] == '':\n",
    "#             XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]/div/div[' + str(iter_val) + ']/div/div/div/div[1]/@data-url')\n",
    "        \n",
    "#         hotel_url.append('https://www.tripadvisor.ca' + str(XPATH)[2:-2])\n",
    "    \n",
    "#     return hotel_url\n",
    "# In [8]:\n",
    "# def get_hotel_url_related(count, html):\n",
    "#     \"\"\"\"\"\n",
    "#     Input: \n",
    "#     -----\n",
    "#         count- Number of desired elements(here the 'divs' containing hotel URLs) present in the downloaded page.\n",
    "#         html- lxml.etree instance(html), used to parse the file.\n",
    "    \n",
    "#     Output:\n",
    "#     ------\n",
    "#         return the extracted full hotel URL(hotel_url) from the base webpage.\n",
    "    \n",
    "#     Functionality:\n",
    "#     -------------\n",
    "#         - Parse the downloaded file using html.etree and XPATH to obtain hotel URLs embedded in the mainpage.\n",
    "#         - This function considers only related search results (if exact results are nil, this will be called)\n",
    "#           for a given category of hotels.\n",
    "#     \"\"\"\"\"\n",
    "#     hotel_url = []\n",
    "#     double_count = 0\n",
    "#     num_ad = 2 # to counter ads intbetween\n",
    "#     iter_val = 0\n",
    "    \n",
    "#     # Parse html page to get the urls for nested webpages.\n",
    "#     for element in range(int(count)):\n",
    "#         iter_val = element + 1\n",
    "#         # Adjust numbering based on webpage structure.\n",
    "#         if iter_val <= 4 :\n",
    "#             iter_val = iter_val\n",
    "#         elif iter_val == int(count):\n",
    "#             iter_val += int(double_count * num_ad) \n",
    "#         else:\n",
    "#             if (iter_val % 5 == 0) & (iter_val != int(count)):\n",
    "#                 double_count += 1\n",
    "#                 iter_val += int(double_count * num_ad)\n",
    "#             else:\n",
    "#                 iter_val += int(double_count * num_ad)\n",
    "#         value = iter_val + 1\n",
    "    \n",
    "#         # Use xpath to retrieve the necessary content.\n",
    "#         XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_filtered_out_hotels_0\"]/div/div[' + str(value) + ']/div/div[1]/@data-url')\n",
    "        \n",
    "#         if str(XPATH)[2:-2] == '':\n",
    "#             XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_filtered_out_hotels_0\"]/div[' + str(value) + ']/div/div[1]/@data-url')\n",
    "\n",
    "#         hotel_url.append('https://www.tripadvisor.ca' + str(XPATH)[2:-2])\n",
    "    \n",
    "#     return hotel_url\n",
    "# In [9]:\n",
    "# def get_hotel_url_nomatches(count, html):\n",
    "#     \"\"\"\"\"\n",
    "#     Input: \n",
    "#     -----\n",
    "#         count- Number of desired elements(here the 'divs' containing hotel URLs) present in the downloaded page.\n",
    "#         html- lxml.etree instance(html), used to parse the file.\n",
    "    \n",
    "#     Output:\n",
    "#     ------\n",
    "#         return the extracted full hotel URL(hotel_url) from the base webpage.\n",
    "    \n",
    "#     Functionality:\n",
    "#     -------------\n",
    "#         - Parse the downloaded file using html.etree and XPATH to obtain hotel URLs embedded in the mainpage.\n",
    "#         - This function considers only other search results (if exact results and related results for a page are nil, \n",
    "#           this will be called) for a given category of hotels.\n",
    "#     \"\"\"\"\"\n",
    "#     hotel_url = []\n",
    "#     double_count = 0\n",
    "#     num_ad = 2 # to counter ads intbetween\n",
    "#     iter_val = 0\n",
    "    \n",
    "#     # Parse html page to get the urls for nested webpages.\n",
    "#     for element in range(int(count)):\n",
    "#         iter_val = element + 1\n",
    "#         # Adjust numbering based on webpage structure.\n",
    "#         if iter_val <= 4 :\n",
    "#             iter_val = iter_val\n",
    "#         elif iter_val == int(count):\n",
    "#             iter_val += int(double_count * num_ad) \n",
    "#         else:\n",
    "#             if (iter_val % 5 == 0) & (iter_val != int(count)):\n",
    "#                 double_count += 1\n",
    "#                 iter_val += int(double_count * num_ad)\n",
    "#             else:\n",
    "#                 iter_val += int(double_count * num_ad)\n",
    "    \n",
    "#         # Use xpath to retrieve the necessary content.\n",
    "#         XPATH = html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_ab_hotels_sponsored_0\"]/div[' + str(iter_val) + ']/div/div[1]/@data-url')\n",
    "        \n",
    "#         if str(XPATH)[2:-2] == '':\n",
    "#             XPATH =  html.xpath('//*[@id=\"taplc_hsx_hotel_list_lite_dusty_ab_hotels_sponsored_0\"]/div[' + str(iter_val) + ']/div/div/div/div[1]/@data-url')\n",
    "\n",
    "#         hotel_url.append('https://www.tripadvisor.ca' + str(XPATH)[2:-2])\n",
    "    \n",
    "#     return hotel_url\n",
    "# In [8]:\n",
    "# # Extract related content from the tree using XPath for the MainPage of TripAdvisor hotels canada.\n",
    "# count_file = 0\n",
    "\n",
    "# # Request html page\n",
    "# url = str('https://www.tripadvisor.ca/Hotels-g153339-Canada-Hotels.html')\n",
    "# html, count_file = download_html_page(url, count_file)\n",
    "\n",
    "# # Create xpath to access necessary content\n",
    "# XPATH_MAINPAGE = '//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]//div[@class=\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"]'\n",
    "# hotel_main_page = html.xpath(XPATH_MAINPAGE)\n",
    "\n",
    "# # Get count of elements of interest in html page\n",
    "# count = html.xpath('count(//*[@id=\"taplc_hsx_hotel_list_lite_dusty_hotels_combined_sponsored_0\"]//div[@class=\"prw_rup prw_meta_hsx_responsive_listing ui_section listItem\"])')\n",
    "# # print(count)\n",
    "\n",
    "# # Get the parsed html etree\n",
    "# hotel_url_returned = get_hotel_url(count, html)\n",
    "# print('Content Extracted..')\n",
    "# TripAdvisor- hotel HTML page downloaded successfully..\n",
    "# File read successfully..\n",
    "# Content Extracted..\n",
    "# In [9]:\n",
    "# # Convert list to dataframe\n",
    "# hotel_url_df = pd.DataFrame(np.array(hotel_url_returned))\n",
    "# print(hotel_url_df[:30])\n",
    "# print('30 Hotel URLs retrieved..')\n",
    "\n",
    "# #  Write to csv file\n",
    "# hotel_url_df.to_csv('Project-Dataset/final-data/file_mainpage_url.txt', index=False)\n",
    "# print('Written on to file..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from lxml import html,etree\n",
    "import requests,re\n",
    "import os,sys\n",
    "import unicodecsv as csv\n",
    "import argparse\n",
    "\n",
    "def parse(locality,checkin_date,checkout_date,sort):\n",
    "    checkIn = checkin_date.strftime(\"%Y/%m/%d\")\n",
    "    checkOut = checkout_date.strftime(\"%Y/%m/%d\")\n",
    "    print (\"Scraper Inititated for Locality:%s\"%locality)\n",
    "    # TA rendering the autocomplete list using this API\n",
    "    print (\"Finding search result page URL\")\n",
    "    geo_url = 'https://www.tripadvisor.com/TypeAheadJson?action=API&startTime='+str(int(time()))+'&uiOrigin=GEOSCOPE&source=GEOSCOPE&interleaved=true&types=geo,theme_park&neighborhood_geos=true&link_type=hotel&details=true&max=12&injectNeighborhoods=true&query='+locality\n",
    "    api_response  = requests.get(geo_url, verify=False).json()\n",
    "    #getting the TA url for th equery from the autocomplete response\n",
    "    url_from_autocomplete = \"http://www.tripadvisor.com\"+api_response['results'][0]['url']\n",
    "    print ('URL found %s'%url_from_autocomplete)\n",
    "    geo = api_response['results'][0]['value']   \n",
    "    #Formating date for writing to file \n",
    "    \n",
    "    date = checkin_date.strftime(\"%Y_%m_%d\")+\"_\"+checkout_date.strftime(\"%Y_%m_%d\")\n",
    "    #form data to get the hotels list from TA for the selected date\n",
    "    form_data = {'changeSet': 'TRAVEL_INFO',\n",
    "            'showSnippets': 'false',\n",
    "            'staydates':date,\n",
    "            'uguests': '2',\n",
    "            'sortOrder':sort\n",
    "    }\n",
    "    #Referrer is necessary to get the correct response from TA if not provided they will redirect to home page\n",
    "    headers = {\n",
    "                            'Accept': 'text/javascript, text/html, application/xml, text/xml, */*',\n",
    "                            'Accept-Encoding': 'gzip,deflate',\n",
    "                            'Accept-Language': 'en-US,en;q=0.5',\n",
    "                            'Cache-Control': 'no-cache',\n",
    "                            'Connection': 'keep-alive',\n",
    "                            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n",
    "                            'Host': 'www.tripadvisor.com',\n",
    "                            'Pragma': 'no-cache',\n",
    "                            'Referer': url_from_autocomplete,\n",
    "                            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:28.0) Gecko/20100101 Firefox/28.0',\n",
    "                            'X-Requested-With': 'XMLHttpRequest'\n",
    "                        }\n",
    "    cookies=  {\"SetCurrency\":\"USD\"}\n",
    "    print (\"Downloading search results page\")\n",
    "    page_response  = requests.post(url = url_from_autocomplete,data=form_data,headers = headers, cookies = cookies, verify=False)\n",
    "    print( \"Parsing results \")\n",
    "    parser = html.fromstring(page_response.text)\n",
    "    hotel_lists = parser.xpath('//div[contains(@class,\"listItem\")]//div[contains(@class,\"listing collapsed\")]')\n",
    "    hotel_data = []\n",
    "    if not hotel_lists:\n",
    "        hotel_lists = parser.xpath('//div[contains(@class,\"listItem\")]//div[@class=\"listing \"]')\n",
    "\n",
    "    for hotel in hotel_lists:\n",
    "        XPATH_HOTEL_LINK = './/a[contains(@class,\"property_title\")]/@href'\n",
    "        XPATH_REVIEWS  = './/a[@class=\"review_count\"]//text()'\n",
    "        XPATH_RANK = './/div[@class=\"popRanking\"]//text()'\n",
    "        XPATH_RATING = './/span[contains(@class,\"rating\")]/@alt'\n",
    "        XPATH_HOTEL_NAME = './/a[contains(@class,\"property_title\")]//text()'\n",
    "        XPATH_HOTEL_FEATURES = './/div[contains(@class,\"common_hotel_icons_list\")]//li//text()'\n",
    "        XPATH_HOTEL_PRICE = './/div[contains(@data-sizegroup,\"mini-meta-price\")]/text()'\n",
    "        XPATH_VIEW_DEALS = './/div[contains(@data-ajax-preserve,\"viewDeals\")]//text()' \n",
    "        XPATH_BOOKING_PROVIDER = './/div[contains(@data-sizegroup,\"mini-meta-provider\")]//text()'\n",
    "\n",
    "        raw_booking_provider = hotel.xpath(XPATH_BOOKING_PROVIDER)\n",
    "        raw_no_of_deals =  hotel.xpath(XPATH_VIEW_DEALS)\n",
    "        raw_hotel_link = hotel.xpath(XPATH_HOTEL_LINK)\n",
    "        raw_no_of_reviews = hotel.xpath(XPATH_REVIEWS)\n",
    "        raw_rank = hotel.xpath(XPATH_RANK)\n",
    "        raw_rating = hotel.xpath(XPATH_RATING)\n",
    "        raw_hotel_name = hotel.xpath(XPATH_HOTEL_NAME)\n",
    "        raw_hotel_features = hotel.xpath(XPATH_HOTEL_FEATURES)\n",
    "        raw_hotel_price_per_night  = hotel.xpath(XPATH_HOTEL_PRICE)\n",
    "\n",
    "        url = 'http://www.tripadvisor.com'+raw_hotel_link[0] if raw_hotel_link else  None\n",
    "        reviews = ''.join(raw_no_of_reviews).replace(\"reviews\",\"\").replace(\",\",\"\") if raw_no_of_reviews else 0 \n",
    "        rank = ''.join(raw_rank) if raw_rank else None\n",
    "        rating = ''.join(raw_rating).replace('of 5 bubbles','').strip() if raw_rating else None\n",
    "        name = ''.join(raw_hotel_name).strip() if raw_hotel_name else None\n",
    "        hotel_features = ','.join(raw_hotel_features)\n",
    "        price_per_night = ''.join(raw_hotel_price_per_night).encode('utf-8').replace('\\n','') if raw_hotel_price_per_night else None\n",
    "        no_of_deals = re.findall(\"all\\s+?(\\d+)\\s+?\",''.join(raw_no_of_deals))\n",
    "        booking_provider = ''.join(raw_booking_provider).strip() if raw_booking_provider else None\n",
    "\n",
    "        if no_of_deals:\n",
    "            no_of_deals = no_of_deals[0]\n",
    "        else:\n",
    "            no_of_deals = 0\n",
    "            \n",
    "        data = {\n",
    "                    'hotel_name':name,\n",
    "                    'url':url,\n",
    "                    'locality':locality,\n",
    "                    'reviews':reviews,\n",
    "                    'tripadvisor_rating':rating,\n",
    "                    'checkOut':checkOut,\n",
    "                    'checkIn':checkIn,\n",
    "                    'hotel_features':hotel_features,\n",
    "                    'price_per_night':price_per_night,\n",
    "                    'no_of_deals':no_of_deals,\n",
    "                    'booking_provider':booking_provider\n",
    "\n",
    "        }\n",
    "        hotel_data.append(data)\n",
    "    return hotel_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('checkin_date',help = 'Hotel Check In Date (Format: YYYY/MM/DD')\n",
    "    parser.add_argument('checkout_date',help = 'Hotel Chek Out Date (Format: YYYY/MM/DD)')\n",
    "    sortorder_help = \"\"\"\n",
    "    available sort orders are :\\n\n",
    "    priceLow - hotels with lowest price,\n",
    "    distLow : Hotels located near to the search center,\n",
    "    recommended: highest rated hotels based on traveler reviews,\n",
    "    popularity :Most popular hotels as chosen by Tipadvisor users \n",
    "    \"\"\"\n",
    "    parser.add_argument('sort',help = sortorder_help,default ='popularity ')\n",
    "    parser.add_argument('locality',help = 'Search Locality')\n",
    "    args = parser.parse_args()\n",
    "    locality = args.locality\n",
    "    checkin_date = datetime.strptime(args.checkin_date,\"%Y/%m/%d\")\n",
    "    checkout_date = datetime.strptime(args.checkout_date,\"%Y/%m/%d\")\n",
    "    sort= args.sort\n",
    "    checkIn = checkin_date.strftime(\"%Y/%m/%d\")\n",
    "    checkOut = checkout_date.strftime(\"%Y/%m/%d\")\n",
    "    today = datetime.now()\n",
    "   \n",
    "    if today<datetime.strptime(checkIn,\"%Y/%m/%d\") and datetime.strptime(checkIn,\"%Y/%m/%d\")<datetime.strptime(checkOut,\"%Y/%m/%d\"):\n",
    "        data = parse(locality,checkin_date,checkout_date,sort)\n",
    "        print (\"Writing to output file tripadvisor_data.csv\")\n",
    "        with open('tripadvisor_data.csv','w')as csvfile:\n",
    "            fieldnames = ['hotel_name','url','locality','reviews','tripadvisor_rating','checkIn','checkOut','price_per_night','booking_provider','no_of_deals','hotel_features']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in  data:\n",
    "                writer.writerow(row)\n",
    "    #checking whether the entered date is already passed\n",
    "    elif today>datetime.strptime(checkIn,\"%Y/%m/%d\") or today>datetime.strptime(checkOut,\"%Y/%m/%d\"):\n",
    "        print (\"Invalid Checkin date: Please enter a valid checkin and checkout dates,entered date is already passed\")\n",
    "    \n",
    "    elif datetime.strptime(checkIn,\"%Y/%m/%d\")>datetime.strptime(checkOut,\"%Y/%m/%d\"):\n",
    "        print (\"Invalid Checkin date: CheckIn date must be less than checkOut date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import selenium\n",
    "import io\n",
    "import requests\n",
    "import bs4\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from _datetime import datetime\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "options=webdriver.ChromeOptions()\n",
    "options.headless=False\n",
    "prefs={\"profile.default_content_setting_values.notofications\" :2}\n",
    "options.add_experimental_option(\"prefs\",prefs)\n",
    "driver=webdriver.Chrome(\"D:\\Python Exercise\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "driver.get(\"https://www.tripadvisor.in/\")\n",
    "#driver.find_element_by_id(\"brand-quick-links-QuickLinkTileItem__link--1k5lE\").click()\n",
    "#driver.find_element_by_id(\"userId\").send_keys(email)\n",
    "#driver.find_element_by_id(\"pwd\").send_keys(pswd)\n",
    "time.sleep(20)\n",
    "\n",
    "#driver.find_element_by_xpath('//*[@id=\"BODY_BLOCK_JQUERY_REFLOW\"]/span/div[2]').click()\n",
    "#time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"component_4\"]/div/div/div/span[1]/div/div/a').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"c_targeted_flyout_1\"]/div/div/div[1]/div[1]/div/input').send_keys(\"kolkata\",Keys.ENTER)\n",
    "time.sleep(1)\n",
    "\n",
    "url = driver.current_url\n",
    "print(url)\n",
    "\n",
    "responce=requests.get(url)\n",
    "responce=responce.text\n",
    "data=bs4.BeautifulSoup(responce,'lxml')\n",
    "\n",
    "read1=data.select(\".listing_title\")\n",
    "# print(len(read1))\n",
    "# print(read1[0].text)\n",
    "\n",
    "read2=data.select(\".price-wrap \")\n",
    "price=[]\n",
    "for i in read2:\n",
    "    x=i.text\n",
    "    x=x.replace(\"â‚¹\\xa0\",\" \")\n",
    "    x=x.lstrip()\n",
    "    x=x.split(\" \")\n",
    "\n",
    "    if (len(x)>1):\n",
    "        price.append(str(x[1]))\n",
    "    else:\n",
    "        price.append(str(x[0]))\n",
    "print(price)\n",
    "\n",
    "\n",
    "name=[]\n",
    "for i in range(len(read1)):\n",
    "    x=read1[i].text\n",
    "    name.append(x)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(name,price)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atharvas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Using Nominatim with the default \"geopy/1.21.0\" `user_agent` is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`. In geopy 2.0 this will become an exception.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude is :- 9.48870055 \n",
      "longtitude is:- 76.41256410969626\n"
     ]
    }
   ],
   "source": [
    "from  geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "city =\"Alappuzha\"\n",
    "country =\"India\"\n",
    "loc = geolocator.geocode(city+','+ country)\n",
    "print(\"latitude is :-\" ,loc.latitude,\"\\nlongtitude is:-\" ,loc.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  geopy.geocoders import Nominatim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude = 9.5401618, Longitude = 76.33118867409746\n"
     ]
    }
   ],
   "source": [
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "location = locator.geocode(\"North Aryad,Alappuzha, India\")\n",
    "\n",
    "print(\"Latitude = {}, Longitude = {}\".format(location.latitude, location.longitude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude = 9.48870055, Longitude = 76.41256410969626\n"
     ]
    }
   ],
   "source": [
    "location = locator.geocode(\"Alappuzha\")\n",
    "print(\"Latitude = {}, Longitude = {}\".format(location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
